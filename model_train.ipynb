{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ba519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "\n",
    "from hierarchical_semantic_segmentation.model import U2Net_Hierarchical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a382b",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea0cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    \"\"\"Example dataset that yields (image, mask) tuples.\n",
    "\n",
    "    * **image**  – (3, H, W) float32 tensor scaled to [0, 1].\n",
    "    * **mask**   – (H, W) long tensor with class indices.\n",
    "\n",
    "    The dataset must already encode background as a unique class index\n",
    "    (e.g. 0). See `LEVELS` below for the mapping used here.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                root_path = 'hierarchical_semantic_segmentation/Pascal-part',\n",
    "                images_folder = 'JPEGImages', \n",
    "                masks_folder='gt_masks', \n",
    "                split='train',\n",
    "                num_classes=9):\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.resize_shape = (256, 256)\n",
    "        self.root = Path(root_path)\n",
    "        self.images_paths = list((self.root).glob(f\"{images_folder}/*.jpg\"))\n",
    "        self.images_paths_dict={ path.name.split('.')[0]:path  for path in self.images_paths}\n",
    "\n",
    "        self.masks_paths = list((self.root).glob(f\"{masks_folder}/*.npy\"))\n",
    "        self.masks_paths_dict={ path.name.split('.')[0]:path  for path in self.masks_paths}\n",
    "\n",
    "        self.image_transform = transforms.Compose([\n",
    "             transforms.Resize(self.resize_shape, interpolation=Image.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        if split=='train':\n",
    "            with open(root_path+'/train_id.txt') as file:\n",
    "                img_names=file.readlines()\n",
    "                self.img_names = [line[:-1] for line in img_names]\n",
    "            \n",
    "            tmp_names = []\n",
    "            for name in self.img_names:\n",
    "                if name in list(self.images_paths_dict.keys()) and name in list(self.masks_paths_dict.keys()):\n",
    "                    tmp_names.append(name)\n",
    "\n",
    "            img_names=copy.copy(tmp_names)\n",
    "\n",
    "        elif  split=='val':\n",
    "            with open(root_path+'/val_id.txt') as file:\n",
    "                img_names=file.readlines()\n",
    "                self.img_names = [line[:-1] for line in img_names]\n",
    "            \n",
    "            tmp_names = []\n",
    "            for name in self.img_names:\n",
    "                if name in list(self.images_paths_dict.keys()) and name in list(self.masks_paths_dict.keys()):\n",
    "                    tmp_names.append(name)\n",
    "\n",
    "            img_names=copy.copy(tmp_names)\n",
    "        else:\n",
    "            raise Exception('error in split')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_names = self.img_names[idx]\n",
    "\n",
    "        img_path = self.images_paths_dict[img_names]\n",
    "        image = self.image_transform(Image.open(img_path).convert(\"RGB\"))\n",
    "\n",
    "        masks_path = self.masks_paths_dict[img_names]\n",
    "        mask = np.load(masks_path)\n",
    "        mask = np.resize(mask, self.resize_shape)\n",
    "\n",
    "        one_hot_mask = np.eye(self.num_classes)[mask] \n",
    "        one_hot_mask = np.moveaxis(one_hot_mask, -1, 0) \n",
    "\n",
    "        one_hot_mask = torch.as_tensor(one_hot_mask, dtype=torch.long)\n",
    "        mask = torch.as_tensor(mask, dtype=torch.long)\n",
    "        \n",
    "        # print('\\nid=',idx,'img_names',img_names, 'img_shape',image.shape,'mask_shape',mask.shape)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe8999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list({1:0,2:1}.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5021c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path to dataset root\n",
    "root_path = 'hierarchical_semantic_segmentation/Pascal-part'\n",
    "#path to save checkpoints\n",
    "save = \"checkpoints\"\n",
    "\n",
    "epochs = 100\n",
    "batch = 4\n",
    "lr = 1e-4\n",
    "device='cuda'\n",
    "\n",
    "\n",
    "# Data\n",
    "train_ds = SegmentationDataset(root_path, split=\"train\")\n",
    "val_ds = SegmentationDataset(root_path, split=\"val\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "list(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce45a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'hierarchical_semantic_segmentation/Pascal-part'\n",
    "dataset = SegmentationDataset(root_path=root_path, split='train')\n",
    "print(dataset.__len__())\n",
    "\n",
    "plt.imshow(dataset[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd26bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cce46b",
   "metadata": {},
   "source": [
    "# Losses and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7960d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_level_target(gt: torch.Tensor, cls_ids: list[int]) -> torch.Tensor:\n",
    "    \"\"\"Return **remapped** GT where *cls_ids* become {0, …, K‑1}; others→IGNORE.\"\"\"\n",
    "    remapped = torch.full_like(gt, 255)\n",
    "    for new_idx, cid in enumerate(cls_ids):\n",
    "        remapped[gt == cid] = new_idx\n",
    "    return remapped\n",
    "\n",
    "\n",
    "def hierarchical_losses(pred: torch.Tensor, gt: torch.Tensor) -> list[torch.Tensor]:\n",
    "    \"\"\"Compute CE loss at each hierarchy level.\n",
    "\n",
    "    Args:\n",
    "        pred: (B, 9, H, W) logits from U²‑Net (no background channel).\n",
    "        gt:   (B, H, W) ground‑truth with class IDs incl. background.\n",
    "    Returns:\n",
    "        List with three scalar losses [loss0, loss1, loss2].\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    levels = [[1], [2, 3], [4, 5, 6, 7, 8, 9]]\n",
    "    for cls_ids in levels:\n",
    "        tgt = _prepare_level_target(gt, cls_ids)            # (B, H, W)\n",
    "        logits = pred[:, cls_ids, :, :]                     # (B, K, H, W)\n",
    "        losses.append(F.cross_entropy(logits, tgt, ignore_index=255))\n",
    "    return losses\n",
    "\n",
    "\n",
    "def compute_mIoU(pred: torch.Tensor, gt: torch.Tensor, cls_ids: list[int]) -> float:\n",
    "    \"\"\"Mean IoU for given *cls_ids*, ignoring background.\n",
    "\n",
    "    Args:\n",
    "        pred: (B, 9, H, W) logits.\n",
    "        gt:   (B, H, W) labels.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        preds = pred.argmax(dim=1)  # (B, H, W)\n",
    "        ious = []\n",
    "        for cid in cls_ids:\n",
    "            pred_mask = preds == cid\n",
    "            true_mask = gt == cid\n",
    "            intersection = (pred_mask & true_mask).sum().item()\n",
    "            union = (pred_mask | true_mask).sum().item()\n",
    "            if union == 0:\n",
    "                continue  # class absent in both → skip from mean\n",
    "            ious.append(intersection / union)\n",
    "        return float(sum(ious) / max(len(ious), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0c50d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e508d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = U2Net_Hierarchical(num_classes=9)\n",
    "x = torch.randn(2, 3, 512, 512)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y, sides = model(x)\n",
    "\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60117806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optim, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for imgs, gts in tqdm(loader, desc=\"train\", leave=False):\n",
    "        imgs, gts = imgs.to(device, non_blocking=True), gts.to(device, non_blocking=True)\n",
    "        logits, _ = model(imgs)\n",
    "\n",
    "        l0, l1, l2 = hierarchical_losses(logits, gts)\n",
    "        loss = l0 + l1 + l2\n",
    "\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        epoch_loss += loss.item() * imgs.size(0)\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module, loader: DataLoader, device: torch.device):\n",
    "    model.eval()\n",
    "    tot = {k: 0.0 for k in range(3)}\n",
    "    levels = [[1], [2, 3], [4, 5, 6, 7, 8, 9]]\n",
    "    with torch.no_grad():\n",
    "        for imgs, gts in tqdm(loader, desc=\"eval\", leave=False):\n",
    "            imgs, gts = imgs.to(device, non_blocking=True), gts.to(device, non_blocking=True)\n",
    "            logits, _ = model(imgs)\n",
    "            for lvl, cls_ids in enumerate(levels):\n",
    "                tot[lvl] += compute_mIoU(logits, gts, cls_ids) * imgs.size(0)\n",
    "    return {f\"mIoU^{lvl}\": tot[lvl] / len(loader.dataset) for lvl in range(3)}\n",
    "\n",
    "\n",
    "#path to dataset root\n",
    "root_path = 'hierarchical_semantic_segmentation/Pascal-part'\n",
    "#path to save checkpoints\n",
    "save = \"checkpoints\"\n",
    "\n",
    "epochs = 100\n",
    "batch = 4\n",
    "lr = 1e-4\n",
    "device='cuda'\n",
    "\n",
    "# Model\n",
    "model = U2Net_Hierarchical(num_classes=9).to(device)\n",
    "\n",
    "# Data\n",
    "train_ds = SegmentationDataset(root_path, split=\"train\")\n",
    "val_ds = SegmentationDataset(root_path, split=\"val\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Optimiser\n",
    "optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "lr_sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=epochs)\n",
    "\n",
    "save_dir = Path(save); save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    train_loss = train_one_epoch(model, train_loader, optim, device)\n",
    "    metrics = evaluate(model, val_loader, device)\n",
    "    lr_sched.step()\n",
    "\n",
    "    # Logging\n",
    "    print(f\"Epoch {epoch:03d} | loss={train_loss:.4f} | \" + \", \".join(f\"{k}={v:.3f}\" for k, v in metrics.items()))\n",
    "\n",
    "    # Save checkpoint\n",
    "    torch.save({\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optim\": optim.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }, save_dir / f\"checkpoint_{epoch:03d}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602aa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#path to dataset root\n",
    "root_path = 'hierarchical_semantic_segmentation/Pascal-part'\n",
    "#path to save checkpoints\n",
    "save = \"checkpoints\"\n",
    "\n",
    "epochs = 100\n",
    "batch = 4\n",
    "lr = 1e-4\n",
    "device='cuda'\n",
    "\n",
    "\n",
    "# Data\n",
    "train_ds = SegmentationDataset(root_path, split=\"train\")\n",
    "val_ds = SegmentationDataset(root_path, split=\"val\")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "list(train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
